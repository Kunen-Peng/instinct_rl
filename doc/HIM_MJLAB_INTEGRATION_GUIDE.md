# ä½¿ç”¨ä¼˜åŒ–åçš„ HIMPPO ä¸ mjlab ObservationManager é›†æˆæŒ‡å—

## ğŸ“Œ æ¦‚è¿°

æœ¬æŒ‡å—è¯´æ˜å¦‚ä½•åœ¨ mjlab ç¯å¢ƒä¸­ä½¿ç”¨ä¼˜åŒ–åçš„ HIMPPOï¼Œå……åˆ†åˆ©ç”¨ ObservationManager çš„è§‚æµ‹å†å²ç®¡ç†ã€‚

## ğŸ”§ ç¯å¢ƒè®¾ç½®

### ç¬¬ä¸€æ­¥ï¼šç†è§£ ObservationManager çš„è§‚æµ‹å†å²

mjlab çš„ ObservationManager ç®¡ç†è§‚æµ‹å†å²ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š

```python
# åœ¨ mjlab ä¸­é…ç½®è§‚æµ‹
observations:
  policy:
    concatenate_terms: true
    flatten_history_dim: true          # â† å…³é”®ï¼šå±•å¹³ä¸º 1D
    history_length: 10                 # â† å…³é”®ï¼šå­˜å‚¨ 10 æ­¥å†å²
    terms:
      state:
        func: compute_observations    # è®¡ç®—å½“å‰çŠ¶æ€
        
  critic:
    concatenate_terms: true
    terms:
      state:
        func: compute_observations
```

### ç¬¬äºŒæ­¥ï¼šéªŒè¯ CircularBuffer è¾“å‡º

ObservationManager ä½¿ç”¨ CircularBufferï¼Œè¾“å‡ºæ ¼å¼ä¸º **oldest_first**ï¼š

```
CircularBuffer.buffer
[batch_size, history_length, obs_dim]
        â†“
å±•å¹³ï¼ˆflatten_history_dim=trueï¼‰
        â†“
[batch_size, history_length * obs_dim]
[obs_t0, obs_t1, ..., obs_t9]  â† oldest_first é¡ºåº
```

**éªŒè¯æ–¹æ³•**ï¼š
```python
# åœ¨ mjlab ç¯å¢ƒä¸­æ£€æŸ¥
obs = env.get_observations()  # è¿”å› policy obs
obs_shape = obs["policy"].shape
# åº”è¯¥æ˜¯ [num_envs, history_length * num_one_step_obs]
```

## ğŸ¯ é…ç½® Instinct-RL

### ç¬¬ä¸€æ­¥ï¼šåœ¨ Instinct-RL ä¸­è®¾ç½® HIMActorCritic

```yaml
# train_config.yaml
policy:
  class_name: "HIMActorCritic"
  
  # å¿…é¡»ä¸ mjlab çš„ history_length ä¸€è‡´ï¼
  history_size: 10
  
  # è‡ªåŠ¨è®¡ç®—æˆ–æ˜¾å¼æŒ‡å®š
  # num_one_step_obs = total_obs_dim / history_size
  num_one_step_obs: 32  # å¦‚æœæ€»ç»´åº¦æ˜¯ 320ï¼Œåˆ™ 320/10=32
  
  # Actor å’Œ Critic éšè—å±‚ç»´åº¦
  actor_hidden_dims: [512, 256, 128]
  critic_hidden_dims: [512, 256, 128]
  
  # HIMEstimator é…ç½®
  enc_hidden_dims: [128, 64, 16]      # Encoder éšè—å±‚
  tar_hidden_dims: [128, 64]          # Target encoder éšè—å±‚
  num_prototype: 32                   # åŸå‹æ•°é‡ï¼ˆå¯¹æ¯”å­¦ä¹ ï¼‰
  temperature: 3.0                    # æ¸©åº¦å‚æ•°
  
  # ä¸€èˆ¬ä¸éœ€è¦æ”¹
  activation: "elu"
  init_noise_std: 1.0
```

### ç¬¬äºŒæ­¥ï¼šé…ç½® HIMPPO

```yaml
algorithm:
  class_name: "HIMPPO"
  
  # PPO è¶…å‚æ•°
  lr: 1e-4
  gamma: 0.99
  lam: 0.95
  entropy_coef: 0.0
  
  # å…¶ä»– PPO å‚æ•°ä¿æŒä¸å˜
  # ...
```

### ç¬¬ä¸‰æ­¥ï¼šé…ç½® HIMOnPolicyRunnerï¼ˆå¯é€‰ï¼‰

```yaml
runner:
  class_name: "HIMOnPolicyRunner"  # æˆ–ä½¿ç”¨æ ‡å‡† OnPolicyRunner
  
  # æ˜¯å¦ä½¿ç”¨ termination obs è¿›è¡Œæ›´å‡†ç¡®çš„ bootstrap
  use_termination_obs: true
  
  # å…¶ä»– runner å‚æ•°
  num_steps_per_env: 24
  save_interval: 100
  log_interval: 10
```

## ğŸ”— æ•°æ®æµæ•´åˆ

### mjlab â†’ Instinct-RL çš„è§‚æµ‹æµ

```
mjlab ç¯å¢ƒ
    â†“
ObservationManager.compute()
    â†“
CircularBuffer (æ¯ä¸€æ­¥è‡ªåŠ¨æ›´æ–°)
    â†“
flattened å†å² [obs_t0, obs_t1, ..., obs_t9]  (oldest_first)
    â†“
env.get_observations() è¿”å›ç»™ Instinct-RL
    â†“
HIMOnPolicyRunner.rollout_step()
    â†“
HIMActorCritic
    â”œâ”€ HIMEstimator._prepare_obs_input()
    â”‚  â””â”€ ç¡®è®¤æ ¼å¼æ˜¯ oldest_first
    â”œâ”€ æå–æœ€æ–°è§‚æµ‹: obs[:, -num_one_step_obs:]
    â”œâ”€ HIMEstimator.forward()
    â”‚  â””â”€ è¾“å‡º [vel(3), latent(D)]
    â”œâ”€ æ‹¼æ¥: [current_obs, vel, latent]
    â””â”€ Actor/Critic ç½‘ç»œ
```

## ğŸ“ å®Œæ•´é…ç½®ç¤ºä¾‹

### mjlab ç«¯é…ç½®ï¼ˆ`scene_config.yaml` æˆ–ç¯å¢ƒé…ç½®ï¼‰

```yaml
observations:
  policy:
    concatenate_terms: true
    concatenate_dim: -1
    flatten_history_dim: true          # âœ“ å¿…é¡»æ˜¯ true
    history_length: 10                 # âœ“ å­˜å‚¨ 10 æ­¥
    
    terms:
      # å‡è®¾æ€»è§‚æµ‹ç»´åº¦ = 320ï¼Œåˆ™å•æ­¥ç»´åº¦ = 320/10 = 32
      position:
        func: get_robot_position       # ç»´åº¦ 12
      velocity:
        func: get_robot_velocity       # ç»´åº¦ 12
      contact:
        func: get_contact_state        # ç»´åº¦ 8
      # æ€»å…± 32 ç»´
  
  critic:
    concatenate_terms: true
    terms:
      position:
        func: get_robot_position
      velocity:
        func: get_robot_velocity
      contact:
        func: get_contact_state
```

### Instinct-RL ç«¯é…ç½®ï¼ˆ`train_config.yaml`ï¼‰

```yaml
policy:
  class_name: "HIMActorCritic"
  
  # å…³é”®ï¼šå¿…é¡»ä¸ mjlab çš„ history_length ä¸€è‡´
  history_size: 10
  
  # è‡ªåŠ¨è®¡ç®—ï¼š320 / 10 = 32
  # æˆ–æ˜¾å¼è®¾ç½®
  num_one_step_obs: 32
  
  # å…¶ä»–å‚æ•°...
  actor_hidden_dims: [512, 256, 128]
  critic_hidden_dims: [512, 256, 128]
  enc_hidden_dims: [128, 64, 16]
  tar_hidden_dims: [128, 64]

algorithm:
  class_name: "HIMPPO"
  # PPO å‚æ•°...

runner:
  class_name: "HIMOnPolicyRunner"
  use_termination_obs: true
```

## âœ… éªŒè¯æ¸…å•

ä½¿ç”¨å‰ç¡®ä¿ï¼š

- [ ] **ObservationManager é…ç½®**
  - [ ] `flatten_history_dim: true`
  - [ ] `history_length: 10` (æˆ–å…¶ä»–å€¼)
  - [ ] `concatenate_terms: true` (if combining multiple obs terms)

- [ ] **HIMActorCritic é…ç½®**
  - [ ] `history_size` = ObservationManager çš„ `history_length`
  - [ ] `num_one_step_obs` æ­£ç¡®ï¼ˆ= æ€»è§‚æµ‹ç»´åº¦ / history_sizeï¼‰
  - [ ] `enc_hidden_dims[-1]` ä¸å…¶ä»–å‚æ•°å…¼å®¹

- [ ] **è§‚æµ‹ç»´åº¦éªŒè¯**
  ```python
  policy_obs_dim = env.get_obs_format()["policy"]["state"][0]
  num_one_step_obs = policy_obs_dim // history_size
  # åº”è¯¥èƒ½æ•´é™¤ï¼Œæ— ä½™æ•°
  assert policy_obs_dim == num_one_step_obs * history_size
  ```

- [ ] **è¿è¡ŒéªŒè¯è„šæœ¬**
  ```bash
  python test_observation_ordering.py
  # æ‰€æœ‰ 5 ä¸ªæµ‹è¯•åº”è¯¥é€šè¿‡
  ```

- [ ] **æ£€æŸ¥åˆå§‹åŒ–æ—¥å¿—**
  - ä¸åº”è¯¥å‡ºç°"WARNING"å…³äºè§‚æµ‹ç»´åº¦
  - åº”è¯¥çœ‹åˆ°"Auto-computed num_one_step_obs"ï¼ˆå¦‚æœè‡ªåŠ¨è®¡ç®—ï¼‰

## ğŸš€ è®­ç»ƒ

### ä½¿ç”¨ä¼˜åŒ–åçš„ HIMPPO å¼€å§‹è®­ç»ƒ

```bash
# åŸºæœ¬ç”¨æ³•
python -m space_mjlab.scripts.instinct_rl.train \
  Mjlab-Velocity-Rough-Unitree-Go2-InstinctRL \
  --env.scene.num-envs 2048

# æˆ–å¸¦æœ‰è‡ªå®šä¹‰é…ç½®
python -m space_mjlab.scripts.instinct_rl.train \
  Mjlab-Velocity-Rough-Unitree-Go2-InstinctRL \
  --config custom_train_config.yaml \
  --env.scene.num-envs 2048

# æ¢å¤è®­ç»ƒ
python -m space_mjlab.scripts.instinct_rl.train \
  Mjlab-Velocity-Rough-Unitree-Go2-InstinctRL \
  --checkpoint path/to/checkpoint.pt
```

### ç›‘æ§è®­ç»ƒ

```bash
# åœ¨å¦ä¸€ä¸ªç»ˆç«¯æŸ¥çœ‹ TensorBoard
tensorboard --logdir logs/instinct_rl/
```

## ğŸ” æ•…éšœæ’æŸ¥

### é—®é¢˜ 1ï¼šè§‚æµ‹ç»´åº¦ä¸åŒ¹é…

**ç—‡çŠ¶**ï¼š
```
[HIMActorCritic WARNING] Policy obs size (320) != history_size (10) * num_one_step_obs (30)
```

**åŸå› **ï¼š
- `num_one_step_obs` è®¡ç®—é”™è¯¯
- ObservationManager è¿”å›çš„ç»´åº¦ä¸é¢„æœŸä¸åŒ

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# æ­£ç¡®è®¡ç®—
actual_obs_dim = env.get_obs_format()["policy"]["state"][0]
num_one_step_obs = actual_obs_dim // history_size
print(f"Correct num_one_step_obs: {num_one_step_obs}")
```

### é—®é¢˜ 2ï¼šè§‚æµ‹é¡ºåºé”™è¯¯

**ç—‡çŠ¶**ï¼š
```
âŒ Observation ordering is incorrect
âŒ current_obs extraction failed
```

**åŸå› **ï¼š
- ObservationManager çš„ `flatten_history_dim` ä¸æ˜¯ `true`
- è§‚æµ‹é¡ºåºä¸æ˜¯ oldest_first

**è§£å†³æ–¹æ¡ˆ**ï¼š
ç¡®ä¿ mjlab é…ç½®ï¼š
```yaml
observations:
  policy:
    flatten_history_dim: true  # âœ“ å¿…é¡»æ˜¯ true
```

### é—®é¢˜ 3ï¼šè®­ç»ƒä¸æ”¶æ•›

**ç—‡çŠ¶**ï¼š
- å¥–åŠ±æ— æ³•å¢é•¿
- æŸå¤±å€¼å¼‚å¸¸

**åŸå› **ï¼š
- ç‰¹å¾ç»´åº¦ä¸åŒ¹é…
- ObservationManager å’Œ Instinct-RL çš„ history_size ä¸ä¸€è‡´
- è§‚æµ‹é¡ºåºä¸æ­£ç¡®

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# 1. è¿è¡ŒéªŒè¯è„šæœ¬
python test_observation_ordering.py

# 2. æ£€æŸ¥æ—¥å¿—ä¸­çš„ç»´åº¦ä¿¡æ¯
# æŸ¥æ‰¾ "HIMActorCritic" å’Œ "HIMEstimator" çš„è¾“å‡º

# 3. ç¡®è®¤æ‰€æœ‰å†å²é•¿åº¦ç›¸åŒ
grep "history_size" logs/instinct_rl/*.log
```

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. Estimator å­¦ä¹ ç‡

å¦‚æœ estimator å­¦ä¹ ä¸å¥½ï¼Œè°ƒæ•´ï¼š

```yaml
policy:
  enc_hidden_dims: [128, 64, 16]  # å¢åŠ å®¹é‡
  num_prototype: 64               # å¢åŠ åŸå‹æ•°ï¼ˆé€šå¸¸æ›´å¥½ï¼‰
  temperature: 2.0                # é™ä½æ¸©åº¦ï¼ˆæ›´å°–é”ï¼‰
```

### 2. Actor-Critic å¤§å°

æ ¹æ®ä»»åŠ¡å¤æ‚åº¦è°ƒæ•´ï¼š

```yaml
# ç®€å•ä»»åŠ¡
actor_hidden_dims: [256, 128]
critic_hidden_dims: [256, 128]

# å¤æ‚ä»»åŠ¡
actor_hidden_dims: [1024, 512, 256]
critic_hidden_dims: [1024, 512, 256]
```

### 3. å†å²é•¿åº¦

- **çŸ­å†å² (5-10)**ï¼šå¿«é€Ÿååº”ï¼Œä½å»¶è¿Ÿ
- **é•¿å†å² (15-30)**ï¼šæ›´å¥½çš„åŠ¨ä½œé¢„æµ‹

```yaml
# mjlab
history_length: 15

# instinct_rl
history_size: 15
num_one_step_obs: 32  # 320 / 15 â‰ˆ 21 (éœ€è¦è°ƒæ•´è§‚æµ‹)
```

## ğŸ“š ç›¸å…³æ–‡æ¡£

| æ–‡æ¡£ | ç”¨é€” |
|------|------|
| HIM_OPTIMIZATION_SUMMARY.md | ä¼˜åŒ–æ€»ç»“ |
| HIM_OPTIMIZATION_WITH_OBSERVATION_MANAGER.md | è¯¦ç»†ä¼˜åŒ–è¯´æ˜ |
| HIM_OPTIMIZATION_QUICK_REFERENCE.md | å¿«é€Ÿå‚è€ƒ |
| HIM_QUICKSTART.md | å¿«é€Ÿå¼€å§‹ |
| HIM_API_REFERENCE.md | API å‚è€ƒ |
| HIM_CONFIG_EXAMPLES.md | é…ç½®ç¤ºä¾‹ |

## ğŸ’¡ æœ€ä½³å®è·µ

1. **æ€»æ˜¯è¿è¡ŒéªŒè¯è„šæœ¬**
   ```bash
   python test_observation_ordering.py
   ```

2. **æ£€æŸ¥åˆå§‹åŒ–æ—¥å¿—**
   ç¬¬ä¸€æ¬¡è¿è¡Œæ—¶æŸ¥çœ‹æ˜¯å¦æœ‰ç»´åº¦è­¦å‘Š

3. **ä¸€è‡´çš„å†å²é•¿åº¦**
   ç¡®ä¿ mjlab å’Œ Instinct-RL ä½¿ç”¨ç›¸åŒçš„ history_length

4. **å¤‡ä»½é…ç½®**
   ä¿å­˜æœ‰æ•ˆçš„é…ç½®æ–‡ä»¶ä»¥ä¾¿åç»­å‚è€ƒ

5. **é€æ­¥è°ƒè¯•**
   å¦‚æœä¸æ”¶æ•›ï¼Œé€ä¸ªæ”¹å˜è¶…å‚æ•°è€Œä¸æ˜¯åŒæ—¶æ”¹å¤šä¸ª

## ğŸ¯ å¸¸è§å·¥ä½œæµ

### ä»æ ‡å‡† ActorCritic è¿ç§»åˆ° HIM

```yaml
# æ—§é…ç½®
policy:
  class_name: "ActorCritic"

# æ–°é…ç½®ï¼ˆæœ€å°æ”¹åŠ¨ï¼‰
policy:
  class_name: "HIMActorCritic"
  history_size: 10           # æ–°å¢
  num_one_step_obs: 32       # æ–°å¢
  # å…¶ä»–å‚æ•°ä¿æŒä¸å˜
```

### é…ç½® mjlab æ”¯æŒ HIM

```yaml
# åªéœ€ä¸¤ä¸ªæ”¹åŠ¨
observations:
  policy:
    history_length: 10           # â† æ–°å¢æˆ–æ”¹å˜å€¼
    flatten_history_dim: true    # â† ç¡®ä¿æ˜¯ true
    
    # å…¶ä»–é…ç½®ä¿æŒä¸å˜
    terms:
      state:
        func: compute_observations
```

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0  
**æœ€åæ›´æ–°**: 2026-01-19  
**çŠ¶æ€**: âœ… å®Œæˆå’ŒéªŒè¯

ç¥æ‚¨è®­ç»ƒé¡ºåˆ©ï¼å¦‚æœ‰é—®é¢˜ï¼Œè¯·å‚è€ƒç›¸å…³æ–‡æ¡£æˆ–è¿è¡ŒéªŒè¯è„šæœ¬ã€‚
